#!/usr/local/munki/munki-python
from collections import defaultdict
from datetime import timedelta
from decimal import Decimal
import hashlib
import json
import os
import plistlib
import ssl
import subprocess
import sys
import urllib.request
import warnings
import zlib

MANAGED_INSTALLS_DIR = "/Library/Managed Installs"
ARCHIVES_DIR = os.path.join(MANAGED_INSTALLS_DIR, "Archives")
APPLICATION_INVENTORY = os.path.join(MANAGED_INSTALLS_DIR, "ApplicationInventory.plist")

USER_AGENT = "Zentral/munkipostflight 0.6"
ZENTRAL_API_ENDPOINT = "https://%TLS_HOSTNAME%/munki/"  # set during the package build
ZENTRAL_API_SERVER_CERTIFICATE = "%TLS_SERVER_CERTS%"  # set during the package build
ZENTRAL_API_AUTH_TOKEN = "%TOKEN%"  # set during the enrollment in the postinstall script of the enrollment package

SYSTEM_PROFILER = "/usr/sbin/system_profiler"


# OSX apps


def get_osx_app_instances():
    apps = []
    try:
        with open(APPLICATION_INVENTORY, "rb") as f:
            data = plistlib.load(f)
    except IOError:
        print("Could not read application inventory plist")
    else:
        for app_d in data:
            apps.append({'app': {'bundle_id': app_d['bundleid'],
                                 'bundle_name': app_d['CFBundleName'],
                                 'bundle_version_str': app_d['version']},
                         'bundle_path': app_d['path']})
    return apps


# Munki run reports


class ManagedInstallReport(object):
    def __init__(self, filename):
        self.basename = os.path.basename(filename)
        self.sha1sum = self._get_sha1_sum(filename)
        with open(filename, "rb") as f:
            self.data = plistlib.load(f)
        self.start_time = self.data['StartTime']
        self.end_time = self.data.get('EndTime', self.start_time)
        try:
            self.munki_version = self.data['MachineInfo']['munki_version']
        except KeyError:
            self.munki_version = None

    @staticmethod
    def _get_sha1_sum(filename):
        sha1 = hashlib.sha1()
        with open(filename, 'rb') as f:
            # TODO: chunking if the file is big
            sha1.update(f.read())
        return sha1.hexdigest()

    def _events(self):
        events = [(self.start_time, {'type': 'start'})]
        for ir in self.data['InstallResults']:
            events.append((ir.pop('time').strftime('%Y-%m-%d %H:%M:%S +0000'),
                           dict(ir, type='install')))
        for rr in self.data['RemovalResults']:
            events.append((rr.pop('time').strftime('%Y-%m-%d %H:%M:%S +0000'),
                           dict(rr, type='removal')))
        for err in self.data['Errors']:
            events.append((self.end_time, {'type': 'error', 'message': err}))
        for warn in self.data['Warnings']:
            events.append((self.end_time, {'type': 'warning', 'message': warn}))
        events.sort(key=lambda t: t[0])
        return events

    def serialize(self):
        d = {'basename': self.basename,
             'sha1sum': self.sha1sum,
             'run_type': self.data['RunType'],
             'start_time': self.start_time,
             'end_time': self.end_time,
             'events': self._events()}
        if self.munki_version:
            d['munki_version'] = self.munki_version
        return d


def iter_manage_install_reports():
    last_report = os.path.join(MANAGED_INSTALLS_DIR, 'ManagedInstallReport.plist')
    if os.path.exists(last_report):
        yield last_report
    if os.path.isdir(ARCHIVES_DIR):
        for filename in sorted(os.listdir(ARCHIVES_DIR), reverse=True):
            yield os.path.join(ARCHIVES_DIR, filename)


def build_reports_payload(last_seen=None):
    """ Unpacks ManagedInstallReport generator object, initializes MIR objects,
    skips if already processed, otherwise serializes & returns payload"""
    payload = []
    for filepath in iter_manage_install_reports():
        mir = ManagedInstallReport(filepath)
        if last_seen is not None and mir.sha1sum == last_seen:
            break
        payload.append(mir.serialize())
    return payload


# Machine infos


class SystemProfilerReport(object):
    def __init__(self):
        p = subprocess.Popen([SYSTEM_PROFILER, '-xml',
                              'SPHardwareDataType',
                              'SPSoftwareDataType',
                              'SPStorageDataType'],
                             stdout=subprocess.PIPE)
        stdoutdata, _ = p.communicate()
        self.data = plistlib.loads(stdoutdata)

    def _get_data_type(self, data_type):
        for subdata in self.data:
            if subdata['_dataType'] == data_type:
                return subdata

    def get_machine_snapshot(self):
        """ Parses sysprofiler output, returns a dict w/three sub-dicts for
        serial / model, CPU, RAM / OS major-minor-patch"""
        # Hardware
        data = self._get_data_type('SPHardwareDataType')
        if len(data['_items']) != 1:
            raise ValueError('0 or more than one item in a SPHardwareDataType output!')
        item_d = data['_items'][0]

        serial_number = item_d['serial_number']
        system_info = {'hardware_model': item_d['machine_model'],
                       'cpu_type': item_d.get('cpu_type', None)}
        # RAM
        ram_multiplicator = None
        ram_amount, ram_amount_unit = item_d['physical_memory'].split()
        if ram_amount_unit == 'GB':
            ram_multiplicator = 2**30
        elif ram_amount_unit == 'MB':
            ram_multiplicator = 2**20
        else:
            warnings.warn('Unknown ram amount unit {}'.format(ram_amount_unit))
        if ram_multiplicator:
            system_info['physical_memory'] = int(Decimal(ram_amount.replace(",", ".")) * ram_multiplicator)

        # Software
        data = self._get_data_type('SPSoftwareDataType')
        if len(data['_items']) != 1:
            raise ValueError('0 or more than one item in a SPSoftwareDataType output!')
        item_d = data['_items'][0]

        try:
            system_info['computer_name'] = item_d['local_host_name']
        except KeyError:
            pass

        # uptime
        # up 7:21:19:44
        uptime = item_d['uptime'].rsplit(" ", 1)[-1]
        td_kwargs = dict(zip(("seconds", "minutes", "hours", "days"),
                             (int(n) for n in uptime.split(":")[::-1])))
        uptime = int(timedelta(**td_kwargs).total_seconds())

        # OS version
        os_version = item_d['os_version']
        os_name, os_version_str, os_build = os_version.rsplit(' ', 2)
        os_build = os_build.strip('()')
        os_version = {'name': os_name,
                      'build': os_build}
        os_version.update(dict(zip(['major', 'minor', 'patch'],
                                   (int(s) for s in os_version_str.split('.')))))
        return {'serial_number': serial_number,
                'system_info': system_info,
                'os_version': os_version,
                'system_uptime': uptime}


# Microsoft certificates and UUIDs


def parse_dn(dn):
    # TODO: poor man's DN parser
    d = defaultdict(list)
    current_attr = ""
    current_val = ""

    state = "ATTR"
    string_state = "NOT_ESCAPED"
    for c in dn:
        if c == "\\" and string_state == "NOT_ESCAPED":
            string_state = "ESCAPED"
        else:
            if string_state == "NOT_ESCAPED" and c in "=/":
                if c == "=":
                    state = "VAL"
                elif c == "/":
                    state = "ATTR"
                    if current_attr:
                        d[current_attr].append(current_val)
                    current_attr = current_val = ""
            else:
                if state == "ATTR":
                    current_attr += c
                elif state == "VAL":
                    current_val += c
                if string_state == "ESCAPED":
                    string_state = "NOT_ESCAPED"

    if current_attr:
        d[current_attr].append(current_val)
        current_attr = current_val = ""
    return d


def read_cert_info(cert):
    p = subprocess.Popen(["/usr/bin/openssl", "x509", "-noout", "-issuer", "-subject"],
                         stdin=subprocess.PIPE, stdout=subprocess.PIPE)
    stdout, _ = p.communicate(cert.encode("utf-8"))
    info = {}
    for line in stdout.decode("utf-8").splitlines():
        line = line.strip()
        attr, dn = line.split("= ", 1)
        info[attr] = parse_dn(dn.strip())
    return info


def iter_certs():
    # first run, for SHA1 and Keychain
    found_certs = {}
    p = subprocess.Popen(["/usr/bin/security", "find-certificate", "-a", "-Z"], stdout=subprocess.PIPE)
    stdout, _ = p.communicate()
    current_sha1 = None
    for line in stdout.decode("utf-8").splitlines():
        line = line.strip()
        if not line:
            continue
        if line.startswith("SHA-1 hash:"):
            current_sha1 = line.replace("SHA-1 hash:", "").strip()
        elif line.startswith("keychain:"):
            found_certs[current_sha1] = line.replace("keychain:", "").strip('" ')
    # second run, for the PEM values
    p = subprocess.Popen(["/usr/bin/security", "find-certificate", "-a", "-Z", "-p"], stdout=subprocess.PIPE)
    stdout, _ = p.communicate()
    current_cert = current_keychain = current_sha1 = None
    for line in stdout.decode("utf-8").splitlines():
        line = line.strip()
        if not line:
            continue
        if line.startswith("SHA-1 hash:"):
            current_sha1 = line.replace("SHA-1 hash:", "").strip()
            try:
                current_keychain = found_certs[current_sha1]
            except KeyError:
                # TODO: probably a new certificate between the 2 runs...
                current_keychain = None
            continue
        elif "--BEGIN CERTIFICATE--" in line:
            current_cert = ""
        if current_cert is not None:
            current_cert += "{}\n".format(line)
        if "--END CERTIFICATE--" in line:
            yield current_keychain, current_cert.strip(), current_sha1
            current_cert = None


def iter_filtered_certs():
    seen_certs = set([])
    for keychain, cert, sha1 in iter_certs():
        if sha1 in seen_certs:
            continue
        if keychain != "/Library/Keychains/System.keychain":
            # only system keychain certificates
            # TODO: verify
            continue
        cert_info = read_cert_info(cert)
        issuer_dict = cert_info.get("issuer", {})
        issuer_dc = issuer_dict.get("DC")
        issuer_cn = issuer_dict.get("CN", [])
        if issuer_dc == ["net", "windows"] and issuer_cn == ["MS-Organization-Access"] or \
           issuer_cn == ["Microsoft Intune MDM Device CA"] or \
           any("JSS" in cn for cn in issuer_cn):
            yield cert
            seen_certs.add(sha1)


# Company portal user info


def iter_users():
    p = subprocess.Popen(["/usr/bin/dscl", "-plist", ".", "-readall", "/Users",
                          "NFSHomeDirectory", "RealName", "UniqueID"],
                         stdout=subprocess.PIPE)
    stdout, _ = p.communicate()
    for dscl_d in plistlib.loads(stdout):
        user_d = {}
        for dscl_attr, user_attr in (("NFSHomeDirectory", "directory"),
                                     ("RecordName", "username"),
                                     ("RealName", "description"),
                                     ("UniqueID", "uid")):
            dscl_values = dscl_d.get("dsAttrTypeStandard:{}".format(dscl_attr))
            if dscl_values:
                value = dscl_values[0]
                if user_attr == "uid":
                    try:
                        value = int(value)
                    except (TypeError, ValueError):
                        continue
                user_d[user_attr] = value
        if user_d["directory"].startswith("/Users"):
            yield user_d


def get_principal_user():
    # ATM, only the company portal info
    selected_plist_ctime = principal_user = None
    for user_d in iter_users():
        plist_path = os.path.join(
            user_d["directory"],
            "Library/Application Support/com.microsoft.CompanyPortal.usercontext.info"
        )
        try:
            plist_ctime = os.stat(plist_path).st_ctime
        except OSError:
            # plist doesn't exist
            continue
        if plist_ctime < selected_plist_ctime:
            # we have already found a more recent plist
            # TODO: better way to select the principal user?
            # TODO: do it on the client or on the server?
            continue
        try:
            p = subprocess.Popen(["/usr/bin/plutil", "-convert", "json", "-o", "-", plist_path],
                                 stdout=subprocess.PIPE)
            stdout, _ = p.communicate()
            company_portal_info = json.loads(stdout)
        except Exception:
            pass
        else:
            selected_plist_ctime = plist_ctime
            principal_user = {
                "source": {
                    "type": "COMPANY_PORTAL",
                    "properties": {
                        "azure_ad_authority_url": company_portal_info["aadAuthorityUrl"],
                        "version": company_portal_info["version"],
                    },
                },
                "unique_id": company_portal_info["aadUniqueId"],
                "principal_name": company_portal_info["aadUserId"],
            }
    return principal_user


# Zentral Munki API calls


def make_api_request(url, data=None):
    req = urllib.request.Request(url)
    req.add_header('User-Agent', USER_AGENT)
    req.add_header('Authorization', 'MunkiEnrolledMachine {}'.format(ZENTRAL_API_AUTH_TOKEN))
    if data:
        data = json.dumps(data)
        req.add_header('Content-Type', 'application/json')
        data = zlib.compress(data.encode("ascii"), 9)
        req.add_header('Content-Encoding', 'deflate')
    ctx = ssl.create_default_context(cafile=ZENTRAL_API_SERVER_CERTIFICATE or "/private/etc/ssl/cert.pem")
    response = urllib.request.urlopen(req, data=data, context=ctx)
    return json.load(response)


def get_job_details(machine_serial_number):
    url = "{}/job_details/".format(ZENTRAL_API_ENDPOINT.strip('/'))
    return make_api_request(url, {'machine_serial_number': machine_serial_number})


def post_job(data):
    url = "{}/post_job/".format(ZENTRAL_API_ENDPOINT.strip('/'))
    return make_api_request(url, data)


def get_machine_snapshot():
    spr = SystemProfilerReport()
    machine_snapshot = spr.get_machine_snapshot()
    machine_snapshot['pem_certificates'] = list(iter_filtered_certs())
    machine_snapshot['osx_app_instances'] = get_osx_app_instances()
    machine_snapshot["principal_user"] = get_principal_user()
    return machine_snapshot


# Main


if __name__ == '__main__':
    # machine snapshot
    data = {'machine_snapshot': get_machine_snapshot()}

    # run type
    run_type = None
    try:
        run_type = sys.argv[1]
    except IndexError:
        pass

    # get job info
    msn = data['machine_snapshot']['serial_number']
    job_details = get_job_details(msn)
    last_seen_sha1sum = job_details.get('last_seen_sha1sum', None)

    # add the new reports
    data['reports'] = build_reports_payload(last_seen_sha1sum)

    # post the payload to zentral
    post_job(data)

    print('Zentral postflight job OK - '
          'run type %s, last sha1sum %s' % (run_type or "-",
                                            (last_seen_sha1sum or "-")[:7]))
